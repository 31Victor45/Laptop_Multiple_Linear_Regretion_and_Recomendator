{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb589950",
   "metadata": {},
   "source": [
    "# Por Qué se Eligió el Modelo Original y la Disminución del Rendimiento ?\n",
    "\n",
    "En el cuaderno de Jupyter, después de aplicar las técnicas de selección de características (filtro de baja varianza y eliminación por alta multicolinealidad usando VIF), se observó una disminución en el rendimiento del modelo. Esto llevó a la decisión de quedarse con el **modelo original** en lugar del \"modelo optimizado\".\n",
    "\n",
    "---\n",
    "\n",
    "## El Impacto de las Acciones de Optimización\n",
    "\n",
    "Las acciones tomadas para \"optimizar\" el modelo, que incluían un filtro de baja varianza y la eliminación de características con alta multicolinealidad, tuvieron un efecto contraproducente en el rendimiento predictivo del modelo.\n",
    "\n",
    "### 1. Filtro de Baja Varianza\n",
    "\n",
    "* **Acción Tomada**: Se eliminaron características cuya varianza era inferior a un umbral de `0.001`. Las características específicas eliminadas fueron `ScreenPixels_BoxCox`, `CPU_company_Samsung`, `GPU_company_ARM` y `Company_Huawei`.\n",
    "* **Razón del Impacto Negativo**: Aunque la intención es eliminar ruido, es posible que algunas de estas características, a pesar de su baja varianza, contuvieran información sutil pero valiosa para el modelo. En particular, para variables categóricas o binarias, una baja varianza puede significar que una categoría es muy rara, pero si esa rareza es predictiva (por ejemplo, una marca muy exclusiva que siempre tiene un precio alto), eliminarla puede ser perjudicial.\n",
    "\n",
    "### 2. Eliminación por Alta Multicolinealidad (VIF)\n",
    "\n",
    "* **Acción Tomada**: Se eliminaron iterativamente características con un Factor de Inflación de Varianza (VIF) superior a 10. Varias características importantes como `OS_Mac OS X`, `SecondaryStorageType_No`, `OS_Windows 10`, `Inches_BoxCox`, `PrimaryStorage_BoxCox`, `Ram_BoxCox`, `CPU_company_Intel`, `PrimaryStorageType_SSD` y `Weight_BoxCox` fueron eliminadas.\n",
    "* **Razón del Impacto Negativo**: Si bien la multicolinealidad alta puede inflar los errores estándar de los coeficientes y dificultar su interpretación individual, no necesariamente reduce el poder predictivo del modelo en su conjunto. Al eliminar estas variables, incluso si eran redundantes en términos de información, el modelo perdió la capacidad de utilizar esa información (compartida o no) para realizar predicciones precisas. Es decir, aunque las variables estuvieran correlacionadas, su presencia conjunta contribuía a explicar una parte significativa de la varianza de la variable objetivo. Al eliminarlas, se perdió esa capacidad explicativa.\n",
    "\n",
    "---\n",
    "\n",
    "# Comparación de Métricas del Modelo de Regresión Lineal\n",
    "\n",
    "La tabla de comparación de métricas lo demuestra claramente:\n",
    "\n",
    "| Métrica                                  | Original (Entrenamiento) | Optimizado (Entrenamiento) | Original (Prueba)  | Optimizado (Prueba)  |\n",
    "| :--------------------------------------- | -----------------------: | -------------------------: | -----------------: | --------------------:|\n",
    "| R-cuadrado (R²)                          |                   0.8365 |                     0.7001 |             0.8094 |               0.6814 |\n",
    "| R-cuadrado Ajustado (R²_adj)             |                   0.8277 |                     0.6881 |             0.7603 |               0.6236 |\n",
    "| Error Absoluto Medio (MAE)               |                   0.4394 |                     0.6090 |             0.4717 |               0.5954 |\n",
    "| Error Cuadrático Medio (MSE)             |                   0.3195 |                     0.5862 |             0.3297 |               0.5512 |\n",
    "| Raíz del Error Cuadrático Medio (RMSE)   |                   0.5652 |                     0.7656 |             0.5742 |               0.7424 |\n",
    "\n",
    "---\n",
    "\n",
    "## Análisis de la Tabla:\n",
    "\n",
    "* **R-cuadrado ($R^2$) y R-cuadrado Ajustado ($R^2_{adj}$)**: Ambas métricas disminuyeron significativamente en el modelo optimizado, tanto en el conjunto de entrenamiento como en el de prueba.\n",
    "    * $R^2_{original\\_train} = 0.8365$ vs $R^2_{optimized\\_train} = 0.7001$\n",
    "    * $R^2_{original\\_test} = 0.8094$ vs $R^2_{optimized\\_test} = 0.6814$\n",
    "    * Esto indica que el modelo optimizado explica una proporción mucho menor de la varianza de la variable dependiente en comparación con el modelo original.\n",
    "* **Error Absoluto Medio (MAE), Error Cuadrático Medio (MSE) y Raíz del Error Cuadrático Medio (RMSE)**: Todas estas métricas de error aumentaron en el modelo optimizado, lo que significa un peor rendimiento.\n",
    "    * $MAE_{original\\_test} = 0.4717$ vs $MAE_{optimized\\_test} = 0.5954$\n",
    "    * $RMSE_{original\\_test} = 0.5742$ vs $RMSE_{optimized\\_test} = 0.7424$\n",
    "    * Un aumento en estas métricas de error significa que las predicciones del modelo optimizado son, en promedio, más lejanas a los valores reales que las predicciones del modelo original.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusión Final:\n",
    "\n",
    "Basándonos en estas métricas, se concluye que la selección de características aplicada para la optimización fue **demasiado agresiva** para este dataset y para este modelo. Las características eliminadas, ya sea por el filtro de baja varianza o por la alta multicolinealidad, contenían **información predictiva valiosa** que era utilizada por el modelo original para lograr predicciones más precisas. Por lo tanto, se optó por conservar el **modelo original**, ya que demostró un rendimiento superior en general."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2189dee",
   "metadata": {},
   "source": [
    "# Regresión Lineal Múltiple\n",
    "\n",
    "La **regresión lineal múltiple** es una técnica estadística que se utiliza para modelar la relación entre una **variable dependiente continua** (la que queremos predecir) y **dos o más variables independientes** (las que usamos para predecir). Es una extensión de la regresión lineal simple, que nos permite considerar el efecto combinado de múltiples factores en el resultado que estamos estudiando.\n",
    "\n",
    "---\n",
    "\n",
    "## Ecuación del Modelo\n",
    "\n",
    "El modelo de regresión lineal múltiple se expresa matemáticamente de la siguiente manera:\n",
    "\n",
    "$$y_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\dots + \\beta_p x_{ip} + \\epsilon_i$$\n",
    "\n",
    "Donde:\n",
    "* $y_i$: Es el valor de la **variable dependiente** para la observación $i$.\n",
    "* $\\beta_0$: Es el **intercepto** (o término constante), el valor esperado de $y$ cuando todas las variables predictoras son cero.\n",
    "* $\\beta_1, \\beta_2, \\dots, \\beta_p$: Son los **coeficientes de regresión** para cada una de las $p$ variables independientes. Cada $\\beta_j$ representa el cambio promedio en $y$ por cada unidad de cambio en $x_j$, **manteniendo constantes todas las demás variables predictoras**.\n",
    "* $x_{i1}, x_{i2}, \\dots, x_{ip}$: Son los valores de las $p$ **variables independientes** para la observación $i$.\n",
    "* $\\epsilon_i$: Es el **término de error** (o residuo) para la observación $i$. Representa la variación en $y$ no explicada por el modelo y se asume que sigue una distribución normal con media cero y varianza constante.\n",
    "\n",
    "---\n",
    "\n",
    "## Supuestos Clásicos del Modelo (MCO)\n",
    "\n",
    "Para obtener estimaciones fiables y poder realizar inferencias estadísticas válidas, el modelo de regresión lineal múltiple, cuando se estima por Mínimos Cuadrados Ordinarios (MCO), se basa en varios supuestos clave:\n",
    "\n",
    "1.  **Linealidad**: La relación entre la variable dependiente y las variables independientes es lineal.\n",
    "    * Matemáticamente: $y_i = \\beta_0 + \\sum_{j=1}^{p} \\beta_j x_{ij} + \\epsilon_i$\n",
    "2.  **Independencia de los Errores**: Los términos de error ($\\epsilon_i$) son independientes entre sí.\n",
    "    * Matemáticamente: $Cov(\\epsilon_i, \\epsilon_j) = 0$ para $i \\neq j$\n",
    "3.  **Homoscedasticidad**: La varianza de los errores es constante para todos los niveles de las variables predictoras.\n",
    "    * Matemáticamente: $Var(\\epsilon_i) = \\sigma^2$ (constante)\n",
    "4.  **Normalidad de los Errores**: Los términos de error ($\\epsilon_i$) siguen una distribución normal con media cero.\n",
    "    * Matemáticamente: $\\epsilon_i \\sim N(0, \\sigma^2)$\n",
    "5.  **No Multicolinealidad Perfecta**: No existe una relación lineal perfecta entre dos o más variables independientes.\n",
    "6.  **Media Cero de los Errores**: La media de los términos de error es cero.\n",
    "    * Matemáticamente: $E(\\epsilon_i) = 0$\n",
    "\n",
    "---\n",
    "\n",
    "## Estimación de los Coeficientes (MCO)\n",
    "\n",
    "Los coeficientes de regresión ($\\beta_j$) se estiman utilizando el método de **Mínimos Cuadrados Ordinarios (MCO)**. Este método busca minimizar la suma de los cuadrados de los residuos, que es la diferencia entre los valores observados de $y$ y los valores predichos por el modelo.\n",
    "\n",
    "La **función a minimizar** es:\n",
    "\n",
    "$$SSR = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 = \\sum_{i=1}^{n} (y_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_{i1} + \\dots + \\hat{\\beta}_p x_{ip}))^2$$\n",
    "\n",
    "En **forma matricial**, las **estimaciones de los coeficientes MCO** se obtienen por la fórmula:\n",
    "\n",
    "$$\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}$$\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretación de los Coeficientes\n",
    "\n",
    "* $\\hat{\\beta}_0$: Representa el **valor esperado de $y$ cuando todas las variables predictoras son cero**.\n",
    "* $\\hat{\\beta}_j$: Representa el **cambio promedio en la variable dependiente $y$ por cada aumento de una unidad en la variable predictora $x_j$**, **manteniendo constantes todas las demás variables predictoras** en el modelo.\n",
    "\n",
    "---\n",
    "\n",
    "## Medidas de Bondad de Ajuste\n",
    "\n",
    "Para evaluar qué tan bien el modelo se ajusta a los datos, se utilizan:\n",
    "\n",
    "### 1. Coeficiente de Determinación ($R^2$)\n",
    "\n",
    "Mide la **proporción de la varianza total de la variable dependiente que es explicada por el modelo**. Varía entre 0 y 1.\n",
    "\n",
    "$$R^2 = 1 - \\frac{SSR_{residual}}{SSR_{total}}$$\n",
    "\n",
    "### 2. Coeficiente de Determinación Ajustado ($R^2_{adj}$)\n",
    "\n",
    "Penaliza la inclusión de variables predictoras innecesarias y es más útil para comparar modelos con un número diferente de variables.\n",
    "\n",
    "$$R^2_{adj} = 1 - (1 - R^2) \\frac{n - 1}{n - p - 1}$$\n",
    "\n",
    "### 3. Error Estándar de la Regresión (SER o $s_e$)\n",
    "\n",
    "Mide la **desviación estándar de los residuos** y representa la precisión de las predicciones del modelo en las unidades de la variable dependiente.\n",
    "\n",
    "$$s_e = \\sqrt{\\frac{SSR_{residual}}{n - p - 1}}$$\n",
    "\n",
    "---\n",
    "\n",
    "## Pruebas de Hipótesis\n",
    "\n",
    "### 1. Prueba F Global (ANOVA)\n",
    "\n",
    "Evalúa la **significancia estadística global del modelo**.\n",
    "* **Hipótesis Nula ($H_0$)**: $\\beta_1 = \\beta_2 = \\dots = \\beta_p = 0$ (ninguna variable predictora tiene un efecto significativo).\n",
    "* **Hipótesis Alternativa ($H_1$)**: Al menos un $\\beta_j \\neq 0$ (el modelo es globalmente significativo).\n",
    "\n",
    "El **estadístico F** se calcula como:\n",
    "\n",
    "$$F = \\frac{SSR_{modelo} / p}{SSR_{residual} / (n - p - 1)}$$\n",
    "\n",
    "### 2. Pruebas t para Coeficientes Individuales\n",
    "\n",
    "Evalúan la **significancia estadística de cada coeficiente de regresión individual**.\n",
    "* **Hipótesis Nula ($H_0$)**: $\\beta_j = 0$ (la variable $x_j$ no tiene un efecto significativo).\n",
    "* **Hipótesis Alternativa ($H_1$)**: $\\beta_j \\neq 0$ (la variable $x_j$ tiene un efecto significativo).\n",
    "\n",
    "El **estadístico t** para cada coeficiente $\\hat{\\beta}_j$ se calcula como:\n",
    "\n",
    "$$t_j = \\frac{\\hat{\\beta}_j}{SE(\\hat{\\beta}_j)}$$\n",
    "\n",
    "---\n",
    "\n",
    "## Limitaciones y Consideraciones\n",
    "\n",
    "* **Sensibilidad a Outliers**: El modelo MCO es sensible a valores atípicos.\n",
    "* **Multicolinealidad**: La alta correlación entre variables predictoras puede afectar la estabilidad de los coeficientes.\n",
    "* **Causalidad vs. Correlación**: La regresión lineal establece correlaciones, no necesariamente causalidad.\n",
    "* **Extrapolación**: Las predicciones fuera del rango de los datos de entrenamiento pueden ser poco fiables.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

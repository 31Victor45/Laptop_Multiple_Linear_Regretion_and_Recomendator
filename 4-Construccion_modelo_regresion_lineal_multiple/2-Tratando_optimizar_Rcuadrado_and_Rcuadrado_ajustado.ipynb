{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbfd6b62",
   "metadata": {},
   "source": [
    "# Mejorando $R^2$ y el $R^2$ ajustado\n",
    "\n",
    "En este notebook es una extencion del anterior ya que en este me quiero centrar en mejorar el $R^2$ y el $R^2$ ajustado con la finalidad de obtener un mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32a4a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Cargamos datos y preprocesamiento inicial (del código anterior) \n",
    "df_laptops = pd.read_csv(\"data/df_model_ready.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9840dfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando el modelo ORIGINAL para obtener sus métricas...\n"
     ]
    }
   ],
   "source": [
    "# Las variables con las que trabajaremos\n",
    "numerical_boxcox_features = [\n",
    "    'Inches_BoxCox', 'Ram_BoxCox', 'Weight_BoxCox', 'CPU_freq_BoxCox',\n",
    "    'PrimaryStorage_BoxCox', 'SecondaryStorage_BoxCox', 'ScreenPixels_BoxCox'\n",
    "]\n",
    "binary_features = [\n",
    "    'Touchscreen', 'IPSpanel', 'RetinaDisplay'\n",
    "]\n",
    "categorical_features = [\n",
    "    'Company', 'TypeName', 'OS', 'PrimaryStorageType',\n",
    "    'SecondaryStorageType', 'CPU_company', 'GPU_company'\n",
    "]\n",
    "target_variable = 'Price_euros_BoxCox'\n",
    "all_features = numerical_boxcox_features + binary_features + categorical_features\n",
    "\n",
    "df_encoded = pd.get_dummies(df_laptops, columns=categorical_features, drop_first=True)\n",
    "\n",
    "X = df_encoded.drop(columns=[target_variable])\n",
    "y = df_encoded[target_variable]\n",
    "\n",
    "X = X.loc[:, (X != 0).any(axis=0)]\n",
    "X = X.dropna(axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenamos el modelo ORIGINAL para comparación\n",
    "print(\"Entrenando el modelo ORIGINAL para obtener sus métricas...\")\n",
    "model_original = LinearRegression()\n",
    "model_original.fit(X_train, y_train)\n",
    "\n",
    "# Calculamos métricas del modelo ORIGINAL\n",
    "y_pred_train_original = model_original.predict(X_train)\n",
    "r2_train_original = r2_score(y_train, y_pred_train_original)\n",
    "mae_train_original = mean_absolute_error(y_train, y_pred_train_original)\n",
    "mse_train_original = mean_squared_error(y_train, y_pred_train_original)\n",
    "rmse_train_original = np.sqrt(mse_train_original)\n",
    "\n",
    "n_train_original = len(y_train)\n",
    "k_train_original = X_train.shape[1]\n",
    "r2_adjusted_train_original = 1 - ((1 - r2_train_original) * (n_train_original - 1)) / (n_train_original - k_train_original - 1)\n",
    "\n",
    "y_pred_test_original = model_original.predict(X_test)\n",
    "r2_test_original = r2_score(y_test, y_pred_test_original)\n",
    "mae_test_original = mean_absolute_error(y_test, y_pred_test_original)\n",
    "mse_test_original = mean_squared_error(y_test, y_pred_test_original)\n",
    "rmse_test_original = np.sqrt(mse_test_original)\n",
    "\n",
    "n_test_original = len(y_test)\n",
    "k_test_original = X_test.shape[1]\n",
    "r2_adjusted_test_original = 1 - ((1 - r2_test_original) * (n_test_original - 1)) / (n_test_original - k_test_original - 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142b8262",
   "metadata": {},
   "source": [
    "Hasta aqui no hay nada que no hubieramos visto en el anterior notebook ; pero ahora aplicaremos un filtro de baja varianza y tambien eliminaremos las caracteristicas que presenten una alta multicolinealidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b442b089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aplicando filtro por baja varianza...\n",
      "Características eliminadas por baja varianza: ['ScreenPixels_BoxCox', 'CPU_company_Samsung', 'GPU_company_ARM', 'Company_Huawei']\n",
      "Total de columnas eliminadas por baja varianza: 4\n",
      "\n",
      "Calculando VIFs y eliminando características con alta multicolinealidad...\n",
      "Eliminando 'OS_Mac OS X' debido a VIF alto (inf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\delhy.py\\anaconda3\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eliminando 'SecondaryStorageType_No' debido a VIF alto (534.41)\n",
      "Eliminando 'OS_Windows 10' debido a VIF alto (113.81)\n",
      "Eliminando 'Inches_BoxCox' debido a VIF alto (100.52)\n",
      "Eliminando 'PrimaryStorage_BoxCox' debido a VIF alto (96.30)\n",
      "Eliminando 'Ram_BoxCox' debido a VIF alto (44.25)\n",
      "Eliminando 'CPU_company_Intel' debido a VIF alto (31.23)\n",
      "Eliminando 'PrimaryStorageType_SSD' debido a VIF alto (21.04)\n",
      "Eliminando 'Weight_BoxCox' debido a VIF alto (16.24)\n",
      "\n",
      "Características finales después de la selección por VIF: ['CPU_freq_BoxCox', 'SecondaryStorage_BoxCox', 'Touchscreen', 'IPSpanel', 'RetinaDisplay', 'Company_Apple', 'Company_Asus', 'Company_Chuwi', 'Company_Dell', 'Company_Fujitsu', 'Company_Google', 'Company_HP', 'Company_LG', 'Company_Lenovo', 'Company_MSI', 'Company_Mediacom', 'Company_Microsoft', 'Company_Razer', 'Company_Samsung', 'Company_Toshiba', 'Company_Vero', 'Company_Xiaomi', 'TypeName_Gaming', 'TypeName_Netbook', 'TypeName_Notebook', 'TypeName_Ultrabook', 'TypeName_Workstation', 'OS_Chrome OS', 'OS_Linux', 'OS_No OS', 'OS_Windows 10 S', 'OS_Windows 7', 'OS_macOS', 'PrimaryStorageType_HDD', 'PrimaryStorageType_Hybrid', 'SecondaryStorageType_Hybrid', 'SecondaryStorageType_SSD', 'GPU_company_Intel', 'GPU_company_Nvidia']\n",
      "Número de características finales (después de varianza y VIF): 39\n",
      "Total de columnas eliminadas por VIF: 9\n"
     ]
    }
   ],
   "source": [
    "# Aplicar Selección de Características (Varianza y VIF) ---\n",
    "# Paso de Varianza\n",
    "print(\"\\nAplicando filtro por baja varianza...\")\n",
    "selector = VarianceThreshold(threshold=0.001)\n",
    "num_cols_before_var = X_train.shape[1]\n",
    "selector.fit(X_train)\n",
    "columns_to_keep_var = X_train.columns[selector.get_support()]\n",
    "X_train_filtered_var = X_train[columns_to_keep_var]\n",
    "X_test_filtered_var = X_test[columns_to_keep_var]\n",
    "num_cols_after_var = X_train_filtered_var.shape[1]\n",
    "print(f\"Características eliminadas por baja varianza: {list(set(X_train.columns) - set(X_train_filtered_var.columns))}\")\n",
    "print(f\"Total de columnas eliminadas por baja varianza: {num_cols_before_var - num_cols_after_var}\")\n",
    "\n",
    "# Paso de VIF\n",
    "def calculate_vif(df):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = df.columns\n",
    "    if df.shape[1] == 0:\n",
    "        return pd.DataFrame(columns=[\"feature\", \"VIF\"])\n",
    "\n",
    "    try:\n",
    "        data_for_vif = df.astype(float)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error al convertir DataFrame a float para VIF: {e}\")\n",
    "        print(\"Tipos de datos de las columnas:\", df.dtypes)\n",
    "        raise\n",
    "\n",
    "    data_for_vif = data_for_vif.replace([np.inf, -np.inf], np.nan).dropna(axis=1)\n",
    "\n",
    "    if data_for_vif.shape[1] == 0:\n",
    "        return pd.DataFrame(columns=[\"feature\", \"VIF\"])\n",
    "\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(data_for_vif.values, i) for i in range(data_for_vif.shape[1])]\n",
    "    return vif_data.sort_values(by=\"VIF\", ascending=False)\n",
    "\n",
    "X_train_vif_processed = X_train_filtered_var.copy()\n",
    "for col in X_train_vif_processed.columns:\n",
    "    X_train_vif_processed[col] = pd.to_numeric(X_train_vif_processed[col], errors='coerce')\n",
    "X_train_vif_processed = X_train_vif_processed.replace([np.inf, -np.inf], np.nan).dropna(axis=1)\n",
    "\n",
    "vif_threshold = 10\n",
    "print(\"\\nCalculando VIFs y eliminando características con alta multicolinealidad...\")\n",
    "initial_vif_cols = X_train_vif_processed.shape[1]\n",
    "\n",
    "while True:\n",
    "    if X_train_vif_processed.shape[1] == 0:\n",
    "        print(\"No hay más características para calcular VIF. Saliendo del bucle.\")\n",
    "        break\n",
    "\n",
    "    vifs = calculate_vif(X_train_vif_processed)\n",
    "\n",
    "    if vifs.empty:\n",
    "        print(\"La tabla de VIFs está vacía. Saliendo del bucle.\")\n",
    "        break\n",
    "\n",
    "    if vifs.iloc[0][\"VIF\"] > vif_threshold:\n",
    "        col_to_drop = vifs.iloc[0][\"feature\"]\n",
    "        if col_to_drop in X_train_vif_processed.columns:\n",
    "            X_train_vif_processed = X_train_vif_processed.drop(columns=[col_to_drop])\n",
    "            print(f\"Eliminando '{col_to_drop}' debido a VIF alto ({vifs.iloc[0]['VIF']:.2f})\")\n",
    "        else:\n",
    "            print(f\"Advertencia: La columna '{col_to_drop}' ya no existe en X_train_vif_processed. Saliendo del bucle VIF.\")\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "final_features_after_vif = X_train_vif_processed.columns\n",
    "X_train_final = X_train_filtered_var[final_features_after_vif]\n",
    "X_test_final = X_test_filtered_var[final_features_after_vif]\n",
    "\n",
    "print(f\"\\nCaracterísticas finales después de la selección por VIF: {list(final_features_after_vif)}\")\n",
    "print(f\"Número de características finales (después de varianza y VIF): {X_train_final.shape[1]}\")\n",
    "print(f\"Total de columnas eliminadas por VIF: {initial_vif_cols - X_train_final.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "579e0a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reentrenando el modelo con las características seleccionadas (MODELO OPTIMIZADO)...\n",
      "Modelo optimizado entrenado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "# Reentrenamos el modelo con las características seleccionadas \n",
    "print(\"\\nReentrenando el modelo con las características seleccionadas (MODELO OPTIMIZADO)...\")\n",
    "model_optimized = LinearRegression()\n",
    "model_optimized.fit(X_train_final, y_train)\n",
    "print(\"Modelo optimizado entrenado exitosamente.\")\n",
    "\n",
    "# Evaluamos el modelo optimizado \n",
    "y_pred_train_optimized = model_optimized.predict(X_train_final)\n",
    "r2_train_optimized = r2_score(y_train, y_pred_train_optimized)\n",
    "mae_train_optimized = mean_absolute_error(y_train, y_pred_train_optimized)\n",
    "mse_train_optimized = mean_squared_error(y_train, y_pred_train_optimized)\n",
    "rmse_train_optimized = np.sqrt(mse_train_optimized)\n",
    "\n",
    "n_train_optimized = len(y_train)\n",
    "k_train_optimized = X_train_final.shape[1]\n",
    "r2_adjusted_train_optimized = 1 - ((1 - r2_train_optimized) * (n_train_optimized - 1)) / (n_train_optimized - k_train_optimized - 1)\n",
    "\n",
    "y_pred_test_optimized = model_optimized.predict(X_test_final)\n",
    "r2_test_optimized = r2_score(y_test, y_pred_test_optimized)\n",
    "mae_test_optimized = mean_absolute_error(y_test, y_pred_test_optimized)\n",
    "mse_test_optimized = mean_squared_error(y_test, y_pred_test_optimized)\n",
    "rmse_test_optimized = np.sqrt(mse_test_optimized)\n",
    "\n",
    "n_test_optimized = len(y_test)\n",
    "k_test_optimized = X_test_final.shape[1]\n",
    "r2_adjusted_test_optimized = 1 - ((1 - r2_test_optimized) * (n_test_optimized - 1)) / (n_test_optimized - k_test_optimized - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e476fc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Comparación de Métricas del Modelo de Regresión Lineal\n",
      "\n",
      "| Métrica                                  | Original (Entrenamiento) | Optimizado (Entrenamiento) | Original (Prueba)  | Optimizado (Prueba)  |\n",
      "| ---------------------------------------: | -----------------------: | -------------------------: | -----------------: | --------------------:|\n",
      "| R-cuadrado (R²)                          |                   0.8365 |                     0.7001 |             0.8094 |               0.6814 |\n",
      "| R-cuadrado Ajustado (R²_adj)             |                   0.8277 |                     0.6881 |             0.7603 |               0.6236 |\n",
      "| Error Absoluto Medio (MAE)               |                   0.4394 |                     0.6090 |             0.4717 |               0.5954 |\n",
      "| Error Cuadrático Medio (MSE)             |                   0.3195 |                     0.5862 |             0.3297 |               0.5512 |\n",
      "| Raíz del Error Cuadrático Medio (RMSE)   |                   0.5652 |                     0.7656 |             0.5742 |               0.7424 |\n"
     ]
    }
   ],
   "source": [
    "# Imprimimos la tabla comparativa de métricas \n",
    "print(\"\\n# Comparación de Métricas del Modelo de Regresión Lineal\\n\")\n",
    "print(\"| Métrica                                  | Original (Entrenamiento) | Optimizado (Entrenamiento) | Original (Prueba)  | Optimizado (Prueba)  |\")\n",
    "print(\"| ---------------------------------------: | -----------------------: | -------------------------: | -----------------: | --------------------:|\")\n",
    "print(f\"| {'R-cuadrado (R²)':<40} | {r2_train_original:>24.4f} | {r2_train_optimized:>26.4f} | {r2_test_original:>18.4f} | {r2_test_optimized:>20.4f} |\")\n",
    "print(f\"| {'R-cuadrado Ajustado (R²_adj)':<40} | {r2_adjusted_train_original:>24.4f} | {r2_adjusted_train_optimized:>26.4f} | {r2_adjusted_test_original:>18.4f} | {r2_adjusted_test_optimized:>20.4f} |\")\n",
    "print(f\"| {'Error Absoluto Medio (MAE)':<40} | {mae_train_original:>24.4f} | {mae_train_optimized:>26.4f} | {mae_test_original:>18.4f} | {mae_test_optimized:>20.4f} |\")\n",
    "print(f\"| {'Error Cuadrático Medio (MSE)':<40} | {mse_train_original:>24.4f} | {mse_train_optimized:>26.4f} | {mse_test_original:>18.4f} | {mse_test_optimized:>20.4f} |\")\n",
    "print(f\"| {'Raíz del Error Cuadrático Medio (RMSE)':<40} | {rmse_train_original:>24.4f} | {rmse_train_optimized:>26.4f} | {rmse_test_original:>18.4f} | {rmse_test_optimized:>20.4f} |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbc47ba",
   "metadata": {},
   "source": [
    "### Conclusiones Finales del Modelo de Regresion Lineal Multiple \n",
    "\n",
    "Basándonos en las métricas motradas en la tabla, podemos concluir que la selección de características aplicada fue demasiado agresiva para este dataset y este modelo. Las características que fueron eliminadas (debido a baja varianza o alta multicolinealidad con el umbral de VIF elegido) contenían información predictiva valiosa que el modelo lineal utilizaba para realizar predicciones más precisas.\n",
    "\n",
    "Por tanto nos quedaremos con el modelo original (el realizado en el anterior notebook) para la realizacion del proyecto que estamos realizando"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
